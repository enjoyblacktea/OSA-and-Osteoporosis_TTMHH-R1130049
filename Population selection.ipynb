{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 120984,
     "status": "ok",
     "timestamp": 1733989961113,
     "user": {
      "displayName": "鄭冠浤",
      "userId": "04355871810202063196"
     },
     "user_tz": -480
    },
    "id": "eMR5aNsVXtCS",
    "outputId": "319fbc34-a425-4783-e735-dbde33c39d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: 2017-2022-Meger.csv\n",
      "File name: 2017年呼吸中止症報表.csv\n",
      "File name: 2017年骨密報表.csv\n",
      "File name: 2018年呼吸中止症報表.csv\n",
      "File name: 2018年骨密報表.csv\n",
      "File name: 2019年呼吸中止症報表.csv\n",
      "File name: 2019年骨密報表.csv\n",
      "File name: 2020年呼吸中止症報表.csv\n",
      "File name: 2020年骨密報表.csv\n",
      "File name: 2021年呼吸中止症報表.csv\n",
      "File name: 2021年骨密報表.csv\n",
      "File name: 2022年呼吸中止症報表.csv\n",
      "File name: 2022年骨密報表.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify your base folder path (e.g., \"data\" folder)\n",
    "BASE_PATH = '/home/blacktea/Downloads/Tung/Study/paper/OSA and Osteoporosis'\n",
    "INPUT_PATH = f'{BASE_PATH}/Data Set/csv'\n",
    "\n",
    "# Create a dictionary to store all DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Get all CSV files in the folder and sort them\n",
    "file_list = sorted([f for f in os.listdir(INPUT_PATH) if f.endswith(\".csv\")])\n",
    "\n",
    "# Read each CSV file in the sorted order\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(INPUT_PATH, file_name)\n",
    "    dataframes[file_name] = pd.read_csv(file_path)\n",
    "\n",
    "# Display file names to confirm successful loading\n",
    "for file_name, df in dataframes.items():\n",
    "    print(f\"File name: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1733989974838,
     "user": {
      "displayName": "鄭冠浤",
      "userId": "04355871810202063196"
     },
     "user_tz": -480
    },
    "id": "WlTJCj2xp0iY",
    "outputId": "838cc123-16f2-4807-9758-6a3200c62a14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 matching rows in 2017年呼吸中止症報表.csv\n",
      "Found 197 matching rows in 2018年呼吸中止症報表.csv\n",
      "Found 134 matching rows in 2019年呼吸中止症報表.csv\n",
      "Found 145 matching rows in 2020年呼吸中止症報表.csv\n",
      "Found 123 matching rows in 2021年呼吸中止症報表.csv\n",
      "Found 92 matching rows in 2022年呼吸中止症報表.csv\n",
      "Found 901 matching rows in 2017年骨密報表.csv\n",
      "Found 705 matching rows in 2018年骨密報表.csv\n",
      "Found 693 matching rows in 2019年骨密報表.csv\n",
      "Found 714 matching rows in 2020年骨密報表.csv\n",
      "Found 732 matching rows in 2021年骨密報表.csv\n",
      "Found 703 matching rows in 2022年骨密報表.csv\n",
      "Total samples after filtering: 5480\n",
      "Samples filtered from OSA reports: 1032\n",
      "Samples filtered from BMD reports: 4448\n",
      "There are 0 rows with duplicate 'id_number'\n",
      "Filtered base file saved as '2017-2022-search.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1077660/1721184110.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  selected_rows = pd.concat([selected_rows, matching_rows], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = f'{BASE_PATH}/Data Set/filter'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Specify the base file name and base feature name\n",
    "base_file_name = '2017-2022-Meger.csv'  # Replace with the base file name\n",
    "base_key_feature = 'id_number'  # Replace with the feature name in the base file\n",
    "\n",
    "# Specify the mapping of feature names for other files, format: {\"file_name\": \"feature_name\"}\n",
    "other_key_features = {\n",
    "    '2017年呼吸中止症報表.csv': '去個資編號',\n",
    "    '2018年呼吸中止症報表.csv': '去個資編號',\n",
    "    '2019年呼吸中止症報表.csv': '去個資編號',\n",
    "    '2020年呼吸中止症報表.csv': '去個資編號',\n",
    "    '2021年呼吸中止症報表.csv': '去個資編號',\n",
    "    '2022年呼吸中止症報表.csv': '去個資編號',\n",
    "\n",
    "    '2017年骨密報表.csv': '去個資編號',\n",
    "    '2018年骨密報表.csv': '去個資編號',\n",
    "    '2019年骨密報表.csv': '去個資編號',\n",
    "    '2020年骨密報表.csv': '去個資編號',\n",
    "    '2021年骨密報表.csv': '去個資編號',\n",
    "    '2022年骨密報表.csv': '去個資編號'\n",
    "}\n",
    "\n",
    "# Assuming 'dataframes' contains all uploaded files as a dictionary\n",
    "# Ensure the base file exists in the uploaded files\n",
    "if base_file_name in dataframes:\n",
    "    # Extract the base DataFrame\n",
    "    base_df = dataframes[base_file_name]\n",
    "\n",
    "    # Create a variable to store the filtered base data\n",
    "    selected_rows = pd.DataFrame(columns=base_df.columns)\n",
    "\n",
    "    # Initialize counters\n",
    "    osa_sample_count = 0  # Sample count from OSA files\n",
    "    bmd_sample_count = 0  # Sample count from BMD files\n",
    "\n",
    "    # Filter the base DataFrame based on the feature values from other files\n",
    "    for other_file, feature_name in other_key_features.items():\n",
    "        if other_file in dataframes:\n",
    "            # Extract the feature values from the other file\n",
    "            other_values = set(dataframes[other_file][feature_name])\n",
    "\n",
    "            # Filter the base DataFrame for matching rows and avoid duplicates\n",
    "            matching_rows = base_df[base_df[base_key_feature].isin(other_values) & ~base_df[base_key_feature].isin(selected_rows[base_key_feature])]\n",
    "            selected_rows = pd.concat([selected_rows, matching_rows], ignore_index=True)\n",
    "\n",
    "            # Count the samples from OSA and BMD files\n",
    "            if '呼吸中止症' in other_file:\n",
    "                osa_sample_count += len(matching_rows)\n",
    "            elif '骨密' in other_file:\n",
    "                bmd_sample_count += len(matching_rows)\n",
    "\n",
    "            print(f\"Found {len(matching_rows)} matching rows in {other_file}\")\n",
    "\n",
    "    # Remove duplicate rows (if any) based on 'id_number' after all filtering\n",
    "    selected_rows.drop_duplicates(subset=base_key_feature, inplace=True)\n",
    "\n",
    "    # Display the sample count after filtering\n",
    "    print(f\"Total samples after filtering: {len(selected_rows)}\")\n",
    "    print(f\"Samples filtered from OSA reports: {osa_sample_count}\")\n",
    "    print(f\"Samples filtered from BMD reports: {bmd_sample_count}\")\n",
    "\n",
    "    # Check if there are any duplicate 'id_number's\n",
    "    duplicate_ids = selected_rows[selected_rows.duplicated(subset=base_key_feature, keep=False)]\n",
    "    print(f\"There are {len(duplicate_ids)} rows with duplicate 'id_number'\")\n",
    "\n",
    "    # Save the filtered base file as a new CSV file\n",
    "    selected_rows.to_csv(f'{OUTPUT_PATH}/2017-2022-filter.csv', index=False)\n",
    "    print(\"Filtered base file saved as '2017-2022-search.csv'\")\n",
    "\n",
    "else:\n",
    "    print(f\"Base file '{base_file_name}' not found. Please check the file name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1733989981719,
     "user": {
      "displayName": "鄭冠浤",
      "userId": "04355871810202063196"
     },
     "user_tz": -480
    },
    "id": "uVmngUSKPd7A",
    "outputId": "4bf5a4fd-6ada-485c-c0ef-7d14725b6fea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples selected from OSA reports: 1032\n",
      "Samples selected from BMD reports: 4493\n",
      "Samples selected from OSA reports but not from BMD reports: 987\n",
      "Samples selected from BMD reports but not from OSA reports: 4448\n",
      "Samples selected by both OSA and BMD reports: 45\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'dataframes' contains all uploaded files as a dictionary\n",
    "# Ensure the base file exists in the uploaded files\n",
    "if base_file_name in dataframes:\n",
    "    # Extract the base DataFrame\n",
    "    base_df = dataframes[base_file_name]\n",
    "\n",
    "    # Initialize counters\n",
    "    osa_ids = set()  # Used to store IDs selected by OSA (Sleep Apnea) reports\n",
    "    bmd_ids = set()  # Used to store IDs selected by BMD (Bone Mineral Density) reports\n",
    "\n",
    "    # Filter the base DataFrame based on the feature values from other files\n",
    "    for other_file, feature_name in other_key_features.items():\n",
    "        if other_file in dataframes:\n",
    "            # Extract the feature values from the other file\n",
    "            other_values = set(dataframes[other_file][feature_name])\n",
    "\n",
    "            # Check if it's an OSA or BMD file\n",
    "            if '呼吸中止症' in other_file:\n",
    "                osa_ids.update(other_values)  # Update the IDs selected by OSA reports\n",
    "            elif '骨密' in other_file:\n",
    "                bmd_ids.update(other_values)  # Update the IDs selected by BMD reports\n",
    "\n",
    "    # Select the rows from the base DataFrame that are in the OSA-selected IDs\n",
    "    selected_osa = base_df[base_df[base_key_feature].isin(osa_ids)]\n",
    "    # Select the rows from the base DataFrame that are in the BMD-selected IDs\n",
    "    selected_bmd = base_df[base_df[base_key_feature].isin(bmd_ids)]\n",
    "\n",
    "    # Select the rows that are in both OSA and BMD selected IDs\n",
    "    selected_common = base_df[base_df[base_key_feature].isin(osa_ids.intersection(bmd_ids))]\n",
    "\n",
    "    # Calculate the number of samples selected by only OSA or only BMD\n",
    "    only_osa = selected_osa[~selected_osa[base_key_feature].isin(selected_bmd[base_key_feature])]\n",
    "    only_bmd = selected_bmd[~selected_bmd[base_key_feature].isin(selected_osa[base_key_feature])]\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Samples selected from OSA reports: {len(selected_osa)}\")\n",
    "    print(f\"Samples selected from BMD reports: {len(selected_bmd)}\")\n",
    "    print(f\"Samples selected from OSA reports but not from BMD reports: {len(only_osa)}\")\n",
    "    print(f\"Samples selected from BMD reports but not from OSA reports: {len(only_bmd)}\")\n",
    "    print(f\"Samples selected by both OSA and BMD reports: {len(selected_common)}\")\n",
    "else:\n",
    "    print(f\"Base file '{base_file_name}' not found. Please check the file name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1733990141083,
     "user": {
      "displayName": "鄭冠浤",
      "userId": "04355871810202063196"
     },
     "user_tz": -480
    },
    "id": "YFg_qh8XygsY"
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "INPUT_PATH = f'{BASE_PATH}/Data Set/filter'\n",
    "df = pd.read_csv(f'{INPUT_PATH}/2017-2022-filter.csv')  # Load the CSV data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1733990144724,
     "user": {
      "displayName": "鄭冠浤",
      "userId": "04355871810202063196"
     },
     "user_tz": -480
    },
    "id": "V8_6kFNhxtFw",
    "outputId": "7f69bd1b-180b-4533-9a37-a384e6a85c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicated 'id_number' values.\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate 'id_number' values\n",
    "duplicate_counts = df['id_number'].value_counts()  # Count the occurrences of each 'id_number'\n",
    "\n",
    "# Filter out the 'id_number' values that appear more than once\n",
    "duplicates = duplicate_counts[duplicate_counts > 1]  # Get 'id_number' values with more than one occurrence\n",
    "\n",
    "# Output the duplicate 'id_number' values and their count\n",
    "if not duplicates.empty:  # Check if there are any duplicates\n",
    "    print(\"The following 'id_number' values are duplicated:\")\n",
    "    print(duplicates)  # Print the duplicated 'id_number' and their counts\n",
    "else:\n",
    "    print(\"There are no duplicated 'id_number' values.\")  # Print message if no duplicates found"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNk/xOWCyR9QxO8ajsWR/XK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "test_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
